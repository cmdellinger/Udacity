{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report: WeRateDogs Twitter Account\n",
    "by Charles Dellinger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The goal of this project is perform all the steps in the data wrangling process using the tweets of the WeRateDogs Twitter account.\n",
    "\n",
    "The general steps include:\n",
    "* [Gather](#gather) tweet data from multiple sources\n",
    "* [Assess](#assess) quality and tidiness issues in the data sets\n",
    "* [Clean](#clean) quality and tidiness issues identified during assessment\n",
    "* [Store](#store) cleaned data as a flat file or database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "### Gather\n",
    "The information is present in three different sources:\n",
    "* flat file: `twitter-archive-enhanced.csv`\n",
    "    + provided as a manual download\n",
    "    + contains historical Twitter record from user WeRateDogs\n",
    "    + enhanced with extracted dog name and growth stage jargon\n",
    "* flat file: `image-predictions.tsv`\n",
    "    + provided as a manual download\n",
    "    + contains machine learning image prediction of dog breed\n",
    "* API data: `tweet_json.txt`\n",
    "    + JSON strings for all the tweets still available (not deleted, etc.)\n",
    "    + retrieved using Tweepy, a Python implementation for the Tweepy API\n",
    "    + contains duplicate information  present in the historical Twitter record\n",
    "    + contains additional data such as favorite count and retweet count\n",
    "    \n",
    "After gathering the data using the three methods above, the data was loaded into the following respective DataFrames:\n",
    "* `tweet_archive_df`\n",
    "* `image_predictions_df`\n",
    "* `tweet_json_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "### Assess\n",
    "General assessment was initiated with visual inspection using `.head()` and variable types using `.info()`. While investigating variables, others started to show problems. The cleaning process also uncovered new areas to clean. What follows are the quality and tidiness issues that were discovered.\n",
    "\n",
    "#### Quality Issues:\n",
    "`tweet_archive_df`\n",
    "* tweets archive includes retweets and replies, which are less curated data \n",
    "* datetime column timestamp is a object type (string)\n",
    "* source contains HTML fragments, but the column isn't needed\n",
    "* DataFrame contains extraneous variables to analysis\n",
    "* numerator extraction of decimals extracted the number behind the '.' as the whole number rating\n",
    "* numerators/denominator pairs with denominator above 10 are for multiple dogs\n",
    "* denominators that aren't divisible by 10 are invalid\n",
    "* 'name' column contains non-dog names\n",
    "* manual fixes:\n",
    "    + tweet_id = 855862651834028034 Snoop Dogg is not a real dog\n",
    "\n",
    "`image_predictions_df`\n",
    "* tweeted pictures aren't always of dogs\n",
    "\n",
    "`tweet_json_df`\n",
    "* missing entries from the api versus the id's present in the tweet archive\n",
    "* too much information; a lot of trash fields\n",
    "\n",
    "all files\n",
    "* tweet_id has an inconsistent data type\n",
    "\n",
    "#### Tidy Issues:\n",
    "`tweet_archive_df`\n",
    "* doggo, floofer, pupper, and puppo columns should be one variable column\n",
    "\n",
    "`image_predictions_df`\n",
    "* many columns leading to most probable dog breed\n",
    "\n",
    "`tweet_json_df`\n",
    "* multiple data in several columns\n",
    "    + JSON tree includes compound fields with another dictionary tree\n",
    "* contains duplicate data fields as 'tweet_archive_df'\n",
    "\n",
    "all files\n",
    "* data should be consolidated into one DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### Clean\n",
    "\n",
    "All DataFrames were copied to new tables for editing where the \\*\\_df format changed to \\*\\_clean.\n",
    "\n",
    "The following are the actions that were taken to clean up the issues discovered in the [Assess](#assess) phase.\n",
    "\n",
    "`tweet_archive_df`\n",
    "* Drop the retweets and replies to eliminate qtweets that aren't primary rating pictures from WeRateDogs\n",
    "* Changed 'timestamp' variable from string text to `datetime` objects\n",
    "* Delete extraneous variables not needed for analysis\n",
    "    + 'source' - contains device/interface that was used to post\n",
    "        * deleting source will also fix the residual HTML tags\n",
    "    + 'expanded_urls' - contains url of tweet\n",
    "* Change doggo, floofer, pupper, and puppo from separate columns into one column.\n",
    "    * check for entries with multiple stage\n",
    "    * store 'tweet_id's\n",
    "    * wipe existing fields\n",
    "    * manually update from text\n",
    "    * melt 'doggo', 'floofer', 'pupper', and 'puppo' into 'dog_stage'\n",
    "    * change all 'None' values to 'NaN'\n",
    "* Fix numerators and denominators:\n",
    "    * Re-extract all matches of the numerator and denominator\n",
    "        * Correct numerator regex extraction for decimals\n",
    "        * Correct denominator regex extraction to only get denominators divisible by 10\n",
    "    * Make numerators and denominators consistent:\n",
    "        * Normalize numerators/denominator pairs to a denominator of 10\n",
    "        * Average multiple ratings in a tweet to create a single rating per tweet\n",
    "* Fix dog names column to contain dog names\n",
    "    + tag_pos in the nltk was tried; invalid 'name's were all lowercase\n",
    "    + Remove lowercase entries\n",
    "    + Remove 'None' entries\n",
    "* Manually fixes:\n",
    "    + Delete\n",
    "        * tweet_id = 855862651834028034 (Snoop Dogg is not a real dog)\n",
    "    + 'name'\n",
    "        * \"O\" should be \"O'Malley\"\n",
    "        * \"Gin\" should be \"Gin & Tonic\"\n",
    "\n",
    "`image_predictions_df`\n",
    "* dropped tweets where the image recognition didn't find a dog\n",
    "* consolidated all prediction variables to a variable called 'dog_breed' with the most probable breed \n",
    "* dropped all variables except 'tweet_id' and 'dog_breed'\n",
    "\n",
    "`tweet_json_df`\n",
    "* missing tweet data was determined to be deleted tweets\n",
    "    +  all returned a [response code](https://developer.twitter.com/en/docs/basics/response-codes.html) 144, which most likely means they were deleted\n",
    "* dropped all variables except 'id', 'retweet_count', 'favorite_count', <s>'users'/'followers_count'</s>\n",
    "    + 'followers_count' ended up being the amount of followers at the time of API access\n",
    "* 'id' was changed to 'tweet_id' to facilitate the merge\n",
    "\n",
    "all files:\n",
    "* all tables were merged into one table\n",
    "    + the merge was performed using an left outer join to `tweet_archive_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='store'></a>\n",
    "### Store\n",
    "Since the data was appropriately merged into one table, the cleaned and merged data set was able to be stored as a flat file called `twitter_archive_master.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
