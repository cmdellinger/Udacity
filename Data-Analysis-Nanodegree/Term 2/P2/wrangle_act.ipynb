{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from twitter_api import api # imports tweepy api with keys\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create and/or set directory for data files to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory if it doesn't already exist\n",
    "folder_name = 'project_data'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check for enhanced twitter archive file (provided): `twitter-archive-enhanced.csv`\n",
    "    + If doesn't exist, this file needs to be downloaded from Udacity\n",
    "    + Load data into Pandas DataFrame: `tweet_archive_df` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for twitter_archive_enhanced.csv\n",
    "tweet_archive_file_path = os.path.join(folder_name, 'twitter-archive-enhanced.csv')\n",
    "assert os.path.isfile(tweet_archive_file_path), \"Download twitter-archive-enhanced.csv to '{}'\".format(tweet_archive_file_path)\n",
    "# Load into DataFrame\n",
    "tweet_archive_df = pd.read_csv(tweet_archive_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check for image prediction data file: `image-predictions.tsv`\n",
    "    + If it doesn't exist, download programatically from URL \n",
    "    + Load data into Pandas DataFrame: `image_predictions_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for image-predictions.tsv\n",
    "# if image-predictions.tsv doesn't exist, download programatically\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "predictions_file_path = os.path.join(folder_name, url.split('/')[-1])\n",
    "if not os.path.isfile(predictions_file_path):\n",
    "    with open(predictions_file_path, mode = 'wb') as file:\n",
    "        file.write(requests.get(url).content)\n",
    "# load into DataFrame\n",
    "image_predictions_df = pd.read_csv(predictions_file_path, '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check for twitter json file: `tweet_json.txt`\n",
    "    + If doesn't exist, download Tweet json data using Tweepy library\n",
    "    + Load data into Pandas DataFrame: `tweet_json_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2343 tweets to 'project_data/tweet_json.txt' as JSON\n"
     ]
    }
   ],
   "source": [
    "text_file_name = 'tweet_json.txt'\n",
    "text_file_path = os.path.join(folder_name, text_file_name)\n",
    "\n",
    "def write_tweets(tweepy_statuses, file_path):\n",
    "    \"\"\" Append tweepy Status objects as JSON string to provided file_path \"\"\"\n",
    "    with open(text_file_path, 'a+') as file:\n",
    "        for tweepy_status in tweepy_statuses:\n",
    "            file.write(json.dumps(tweepy_status._json)+'\\n')\n",
    "            \n",
    "# list to sublist generator from:\n",
    "# https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "        \n",
    "def create_tweet_json_file(tweet_ids, file_path):\n",
    "    \"\"\" download and write JSON for provided tweet_ids to provided file_path\"\"\"\n",
    "    for chunk in chunks(tweet_ids, 100):\n",
    "        chunk_statuses = api.statuses_lookup(list(chunk))\n",
    "        write_tweets(chunk_statuses, file_path)\n",
    "    \n",
    "if not os.path.isfile(text_file_path):\n",
    "    tweet_ids = tweet_archive_df.tweet_id\n",
    "    create_tweet_json_file(tweet_ids, text_file_path) #first run contained 2343 JSON strings\n",
    "    print(\"Downloaded {} tweets to '{}' as JSON\".format(sum(1 for line in open(text_file_path)), text_file_path))\n",
    "else:\n",
    "    print(\"{} tweets exist in '{}'\".format(sum(1 for line in open(text_file_path)), text_file_path))\n",
    "    \n",
    "# load into DataFrame\n",
    "tweet_json_df = pd.read_json(text_file_path, lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tweet_json_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine JSON structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contributors': None,\n",
      " 'coordinates': None,\n",
      " 'created_at': 'Tue Aug 01 16:23:56 +0000 2017',\n",
      " 'entities': {'hashtags': [],\n",
      "              'media': [{'display_url': 'pic.twitter.com/MgUWQ76dJU',\n",
      "                         'expanded_url': 'https://twitter.com/dog_rates/status/892420643555336193/photo/1',\n",
      "                         'id': 892420639486877696,\n",
      "                         'id_str': '892420639486877696',\n",
      "                         'indices': [86, 109],\n",
      "                         'media_url': 'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
      "                         'media_url_https': 'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
      "                         'sizes': {'large': {'h': 528,\n",
      "                                             'resize': 'fit',\n",
      "                                             'w': 540},\n",
      "                                   'medium': {'h': 528,\n",
      "                                              'resize': 'fit',\n",
      "                                              'w': 540},\n",
      "                                   'small': {'h': 528,\n",
      "                                             'resize': 'fit',\n",
      "                                             'w': 540},\n",
      "                                   'thumb': {'h': 150,\n",
      "                                             'resize': 'crop',\n",
      "                                             'w': 150}},\n",
      "                         'type': 'photo',\n",
      "                         'url': 'https://t.co/MgUWQ76dJU'}],\n",
      "              'symbols': [],\n",
      "              'urls': [],\n",
      "              'user_mentions': []},\n",
      " 'extended_entities': {'media': [{'display_url': 'pic.twitter.com/MgUWQ76dJU',\n",
      "                                  'expanded_url': 'https://twitter.com/dog_rates/status/892420643555336193/photo/1',\n",
      "                                  'id': 892420639486877696,\n",
      "                                  'id_str': '892420639486877696',\n",
      "                                  'indices': [86, 109],\n",
      "                                  'media_url': 'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
      "                                  'media_url_https': 'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
      "                                  'sizes': {'large': {'h': 528,\n",
      "                                                      'resize': 'fit',\n",
      "                                                      'w': 540},\n",
      "                                            'medium': {'h': 528,\n",
      "                                                       'resize': 'fit',\n",
      "                                                       'w': 540},\n",
      "                                            'small': {'h': 528,\n",
      "                                                      'resize': 'fit',\n",
      "                                                      'w': 540},\n",
      "                                            'thumb': {'h': 150,\n",
      "                                                      'resize': 'crop',\n",
      "                                                      'w': 150}},\n",
      "                                  'type': 'photo',\n",
      "                                  'url': 'https://t.co/MgUWQ76dJU'}]},\n",
      " 'favorite_count': 38623,\n",
      " 'favorited': False,\n",
      " 'geo': None,\n",
      " 'id': 892420643555336193,\n",
      " 'id_str': '892420643555336193',\n",
      " 'in_reply_to_screen_name': None,\n",
      " 'in_reply_to_status_id': None,\n",
      " 'in_reply_to_status_id_str': None,\n",
      " 'in_reply_to_user_id': None,\n",
      " 'in_reply_to_user_id_str': None,\n",
      " 'is_quote_status': False,\n",
      " 'lang': 'en',\n",
      " 'place': None,\n",
      " 'possibly_sensitive': False,\n",
      " 'retweet_count': 8542,\n",
      " 'retweeted': False,\n",
      " 'source': '<a href=\"http://twitter.com/download/iphone\" '\n",
      "           'rel=\"nofollow\">Twitter for iPhone</a>',\n",
      " 'text': \"This is Phineas. He's a mystical boy. Only ever appears in the hole \"\n",
      "         'of a donut. 13/10 https://t.co/MgUWQ76dJU',\n",
      " 'truncated': False,\n",
      " 'user': {'contributors_enabled': False,\n",
      "          'created_at': 'Sun Nov 15 21:41:29 +0000 2015',\n",
      "          'default_profile': False,\n",
      "          'default_profile_image': False,\n",
      "          'description': 'Your Only Source for Pawfessional Dog Ratings STORE: '\n",
      "                         '@ShopWeRateDogs | IG, FB & SC: WeRateDogs | MOBILE '\n",
      "                         'APP: @GoodDogsGame Business: '\n",
      "                         'dogratingtwitter@gmail.com',\n",
      "          'entities': {'description': {'urls': []},\n",
      "                       'url': {'urls': [{'display_url': 'weratedogs.com',\n",
      "                                         'expanded_url': 'http://weratedogs.com',\n",
      "                                         'indices': [0, 23],\n",
      "                                         'url': 'https://t.co/N7sNNHSfPq'}]}},\n",
      "          'favourites_count': 135419,\n",
      "          'follow_request_sent': False,\n",
      "          'followers_count': 7088615,\n",
      "          'following': False,\n",
      "          'friends_count': 9,\n",
      "          'geo_enabled': True,\n",
      "          'has_extended_profile': True,\n",
      "          'id': 4196983835,\n",
      "          'id_str': '4196983835',\n",
      "          'is_translation_enabled': False,\n",
      "          'is_translator': False,\n",
      "          'lang': 'en',\n",
      "          'listed_count': 4688,\n",
      "          'location': '𝓶𝓮𝓻𝓬𝓱 ↴      DM YOUR DOGS',\n",
      "          'name': 'WeRateDogs™',\n",
      "          'notifications': False,\n",
      "          'profile_background_color': '000000',\n",
      "          'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "          'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "          'profile_background_tile': False,\n",
      "          'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4196983835/1525830435',\n",
      "          'profile_image_url': 'http://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg',\n",
      "          'profile_image_url_https': 'https://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg',\n",
      "          'profile_link_color': 'F5ABB5',\n",
      "          'profile_sidebar_border_color': '000000',\n",
      "          'profile_sidebar_fill_color': '000000',\n",
      "          'profile_text_color': '000000',\n",
      "          'profile_use_background_image': False,\n",
      "          'protected': False,\n",
      "          'screen_name': 'dog_rates',\n",
      "          'statuses_count': 7342,\n",
      "          'time_zone': None,\n",
      "          'translator_type': 'none',\n",
      "          'url': 'https://t.co/N7sNNHSfPq',\n",
      "          'utc_offset': None,\n",
      "          'verified': True}}\n"
     ]
    }
   ],
   "source": [
    "# use first tweet as test tweet:\n",
    "test_tweet_id = tweet_archive_df.tweet_id[0]\n",
    "test_tweet_api = api.statuses_lookup([test_tweet_id])\n",
    "# pretty-print JSON of test tweet\n",
    "pprint(test_tweet_api[0]._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'retweet_count', 'favorite_count'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Archive (Enhanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess [Twitter Archive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_archive_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets that are replies\n",
    "# .info() says there should be 78\n",
    "78 == sum(tweet_archive_df.in_reply_to_status_id.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets that are retweets\n",
    "# .info() says there should be 181\n",
    "181 == sum(tweet_archive_df.retweeted_status_id.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check timestamp format\n",
    "tweet_archive_df.timestamp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_archive_df.retweeted_status_user_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues:\n",
    "    * tweets include retweets and replies\n",
    "    * `timestamp` needs to be in datetime format for use in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean [Twitter Archive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to another DataFrame to clean\n",
    "tweet_archive_clean = tweet_archive_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_archive_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Define\n",
    "The `timestamp` column contains string text. To be usable for graphing and analysis, the data in this series needs to be changed to `datetime` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# test strptime format with example string from index 0\n",
    "# datetime.strptime('2017-08-01 16:23:56 +0000','%Y-%m-%d %H:%M:%S %z')\n",
    "\n",
    "# use pd.to_datetime() to change series of string date & time to datetime objects\n",
    "# pd.to_datetime(tweet_archive_clean.timestamp, format='%Y-%m-%d %H:%M:%S %z')\n",
    "\n",
    "# pd.to_datetime() doesn't accept '%z', so create function and map column\n",
    "def string_to_datetime(string):\n",
    "    return datetime.strptime(string,'%Y-%m-%d %H:%M:%S %z')\n",
    "tweet_archive_clean.timestamp = tweet_archive_clean.timestamp.map(string_to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_archive_clean.timestamp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Define\n",
    "Archive contains retweets and replies. The replies and retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df[image_predictions_df.p1_dog == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to another DataFrame to clean\n",
    "image_predictions_clean = image_predictions_df.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
